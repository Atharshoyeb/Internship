{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM4Zv0A/RXS/O+7tZkbe/4S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Atharshoyeb/Internship/blob/main/BeautifulSoupAssignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wyXz_2pS5ap",
        "outputId": "e6186d38-b5c8-448c-8af7-85a770cb7cd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Main Page\n",
            "Welcome to Wikipedia\n",
            "From today's featured article\n",
            "Did you know ...\n",
            "In the news\n",
            "On this day\n",
            "Today's featured picture\n",
            "Other areas of Wikipedia\n",
            "Wikipedia's sister projects\n",
            "Wikipedia languages\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "\n",
        "def display_header_tags(url):\n",
        "    # Send a GET request to the URL\n",
        "    response = requests.get(url)\n",
        "\n",
        "    # Check if the request was successful\n",
        "    if response.status_code == 200:\n",
        "        # Parse the HTML content of the page\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Find all header tags (h1, h2, h3, etc.)\n",
        "        header_tags = soup.find_all(re.compile('^h[1-6]$'))\n",
        "\n",
        "        # Display the text content of each header tag\n",
        "        for tag in header_tags:\n",
        "            print(tag.text.strip())\n",
        "    else:\n",
        "        print(\"Failed to retrieve the page.\")\n",
        "\n",
        "\n",
        "url = \"https://en.wikipedia.org/wiki/Main_Page\"\n",
        "\n",
        "display_header_tags(url)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "def scrape_top_rated_movies(url):\n",
        "    # Send a GET request to the URL\n",
        "    response = requests.get(url)\n",
        "\n",
        "    # Check if the request was successful\n",
        "    if response.status_code == 200:\n",
        "        # Parse the HTML content of the page\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Find the list containing the top-rated movies\n",
        "        movie_list = soup.find('div', class_='lister-list')\n",
        "\n",
        "        # Check if the list was found\n",
        "        if movie_list:\n",
        "            # Initialize lists to store movie data\n",
        "            names = []\n",
        "            ratings = []\n",
        "            years = []\n",
        "\n",
        "            # Extract data for each movie in the list\n",
        "            for movie in movie_list.find_all('div', class_='lister-item-content'):\n",
        "                # Extract movie name\n",
        "                name = movie.find('h3', class_='lister-item-header').a.text.strip()\n",
        "                names.append(name)\n",
        "\n",
        "                # Extract movie rating\n",
        "                rating = movie.find('span', class_='ipl-rating-star__rating').text.strip()\n",
        "                ratings.append(float(rating))\n",
        "\n",
        "                # Extract year of release\n",
        "                year = movie.find('span', class_='lister-item-year').text.strip('()')\n",
        "                years.append(year)\n",
        "\n",
        "            # Create a DataFrame from the extracted data\n",
        "            df = pd.DataFrame({'Name': names, 'Rating': ratings, 'Year': years})\n",
        "\n",
        "            return df\n",
        "        else:\n",
        "            print(\"List containing top-rated movies not found.\")\n",
        "            return None\n",
        "    else:\n",
        "        print(\"Failed to retrieve the page. Status code:\", response.status_code)\n",
        "        return None\n",
        "\n",
        "# URL of IMDb's top-rated movies\n",
        "url = \"https://www.imdb.com/list/ls091520106/\"\n",
        "\n",
        "# Call the function to scrape top-rated movies and create a DataFrame\n",
        "top_rated_movies_df = scrape_top_rated_movies(url)\n",
        "\n",
        "# Display the DataFrame\n",
        "if top_rated_movies_df is not None:\n",
        "    print(top_rated_movies_df)\n",
        "else:\n",
        "    print(\"Failed to scrape top-rated movies.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9lkdAziTxxI",
        "outputId": "72adf677-e197-4499-b3e0-2481fbbc3a72"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                        Name  Rating  Year\n",
            "0   The Shawshank Redemption     9.3  1994\n",
            "1              The Godfather     9.2  1972\n",
            "2      The Godfather Part II     9.0  1974\n",
            "3            The Dark Knight     9.0  2008\n",
            "4               12 Angry Men     9.0  1957\n",
            "..                       ...     ...   ...\n",
            "95        North by Northwest     8.3  1959\n",
            "96        A Clockwork Orange     8.3  1971\n",
            "97                    Snatch     8.2  2000\n",
            "98                    Amélie     8.3  2001\n",
            "99                   The Kid     8.2  1921\n",
            "\n",
            "[100 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def scrape_dineout_details(url):\n",
        "    # Send a GET request to the URL\n",
        "    response = requests.get(url)\n",
        "\n",
        "    # Check if the request was successful\n",
        "    if response.status_code == 200:\n",
        "        # Parse the HTML content of the page\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Find all restaurant cards\n",
        "        restaurant_cards = soup.find_all('div', class_='restnt-card')\n",
        "\n",
        "        # Initialize lists to store details\n",
        "        names = []\n",
        "        cuisines = []\n",
        "        locations = []\n",
        "        ratings = []\n",
        "        image_urls = []\n",
        "\n",
        "        # Extract details for each restaurant\n",
        "        for card in restaurant_cards:\n",
        "            # Extract restaurant name\n",
        "            name_elem = card.find('div', class_='restnt-info cursor')\n",
        "            name = name_elem.text.strip() if name_elem else 'N/A'\n",
        "            names.append(name)\n",
        "\n",
        "            # Extract cuisine\n",
        "            cuisine_elem = card.find('div', class_='restnt-info').find('span', class_='double-line-ellipsis')\n",
        "            cuisine = cuisine_elem.text.strip() if cuisine_elem else 'N/A'\n",
        "            cuisines.append(cuisine)\n",
        "\n",
        "            # Extract location\n",
        "            location_elem = card.find('div', class_='restnt-loc')\n",
        "            location = location_elem.text.strip() if location_elem else 'N/A'\n",
        "            locations.append(location)\n",
        "\n",
        "            # Extract rating\n",
        "            rating_elem = card.find('div', class_='restnt-rating')\n",
        "            rating = rating_elem.text.strip() if rating_elem else 'N/A'\n",
        "            ratings.append(rating)\n",
        "\n",
        "            # Extract image URL\n",
        "            image_url_elem = card.find('div', class_='img-cursor')\n",
        "            image_url = image_url_elem.img['data-src'] if image_url_elem and image_url_elem.img else 'N/A'\n",
        "            image_urls.append(image_url)\n",
        "\n",
        "            # Print details for debugging\n",
        "            print(f\"Name: {name}\")\n",
        "            print(f\"Cuisine: {cuisine}\")\n",
        "            print(f\"Location: {location}\")\n",
        "            print(f\"Rating: {rating}\")\n",
        "            print(f\"Image URL: {image_url}\")\n",
        "            print()\n",
        "\n",
        "        # Print scraped details\n",
        "        for i in range(len(names)):\n",
        "            print(f\"Restaurant Name: {names[i]}\")\n",
        "            print(f\"Cuisine: {cuisines[i]}\")\n",
        "            print(f\"Location: {locations[i]}\")\n",
        "            print(f\"Rating: {ratings[i]}\")\n",
        "            print(f\"Image URL: {image_urls[i]}\")\n",
        "            print()\n",
        "    else:\n",
        "        print(\"Failed to retrieve the page.\")\n",
        "\n",
        "# URL of dineout.co.in\n",
        "url = \"https://www.dineout.co.in/delhi-restaurants/buffet-special\"\n",
        "\n",
        "# Call the function to scrape details and display\n",
        "scrape_dineout_details(url)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMBpy2vmaXwk",
        "outputId": "e37d8e8b-8124-4720-cfb0-2bce0c767868"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: Castle's BarbequeConnaught Place, Central Delhi\n",
            "Cuisine: N/A\n",
            "Location: Connaught Place, Central Delhi\n",
            "Rating: 4\n",
            "Image URL: N/A\n",
            "\n",
            "Name: Cafe KnoshThe Leela Ambience Convention Hotel,Shahdara, East Delhi\n",
            "Cuisine: N/A\n",
            "Location: The Leela Ambience Convention Hotel,Shahdara, East Delhi\n",
            "Rating: 4.3\n",
            "Image URL: N/A\n",
            "\n",
            "Name: India GrillHilton Garden Inn,Saket, South Delhi\n",
            "Cuisine: N/A\n",
            "Location: Hilton Garden Inn,Saket, South Delhi\n",
            "Rating: 3.9\n",
            "Image URL: N/A\n",
            "\n",
            "Name: The Barbeque CompanyGardens Galleria,Sector 38A, Noida\n",
            "Cuisine: N/A\n",
            "Location: Gardens Galleria,Sector 38A, Noida\n",
            "Rating: 3.9\n",
            "Image URL: N/A\n",
            "\n",
            "Name: Delhi BarbequeTaurus Sarovar Portico,Mahipalpur, South Delhi\n",
            "Cuisine: N/A\n",
            "Location: Taurus Sarovar Portico,Mahipalpur, South Delhi\n",
            "Rating: 3.7\n",
            "Image URL: N/A\n",
            "\n",
            "Name: The Monarch - Bar Be Que VillageIndirapuram Habitat Centre,Indirapuram, Ghaziabad\n",
            "Cuisine: N/A\n",
            "Location: Indirapuram Habitat Centre,Indirapuram, Ghaziabad\n",
            "Rating: 3.8\n",
            "Image URL: N/A\n",
            "\n",
            "Name: The Barbeque TimesM2K Corporate Park,Sector 51, Gurgaon\n",
            "Cuisine: N/A\n",
            "Location: M2K Corporate Park,Sector 51, Gurgaon\n",
            "Rating: 4.1\n",
            "Image URL: N/A\n",
            "\n",
            "Restaurant Name: Castle's BarbequeConnaught Place, Central Delhi\n",
            "Cuisine: N/A\n",
            "Location: Connaught Place, Central Delhi\n",
            "Rating: 4\n",
            "Image URL: N/A\n",
            "\n",
            "Restaurant Name: Cafe KnoshThe Leela Ambience Convention Hotel,Shahdara, East Delhi\n",
            "Cuisine: N/A\n",
            "Location: The Leela Ambience Convention Hotel,Shahdara, East Delhi\n",
            "Rating: 4.3\n",
            "Image URL: N/A\n",
            "\n",
            "Restaurant Name: India GrillHilton Garden Inn,Saket, South Delhi\n",
            "Cuisine: N/A\n",
            "Location: Hilton Garden Inn,Saket, South Delhi\n",
            "Rating: 3.9\n",
            "Image URL: N/A\n",
            "\n",
            "Restaurant Name: The Barbeque CompanyGardens Galleria,Sector 38A, Noida\n",
            "Cuisine: N/A\n",
            "Location: Gardens Galleria,Sector 38A, Noida\n",
            "Rating: 3.9\n",
            "Image URL: N/A\n",
            "\n",
            "Restaurant Name: Delhi BarbequeTaurus Sarovar Portico,Mahipalpur, South Delhi\n",
            "Cuisine: N/A\n",
            "Location: Taurus Sarovar Portico,Mahipalpur, South Delhi\n",
            "Rating: 3.7\n",
            "Image URL: N/A\n",
            "\n",
            "Restaurant Name: The Monarch - Bar Be Que VillageIndirapuram Habitat Centre,Indirapuram, Ghaziabad\n",
            "Cuisine: N/A\n",
            "Location: Indirapuram Habitat Centre,Indirapuram, Ghaziabad\n",
            "Rating: 3.8\n",
            "Image URL: N/A\n",
            "\n",
            "Restaurant Name: The Barbeque TimesM2K Corporate Park,Sector 51, Gurgaon\n",
            "Cuisine: N/A\n",
            "Location: M2K Corporate Park,Sector 51, Gurgaon\n",
            "Rating: 4.1\n",
            "Image URL: N/A\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def scrape_former_presidents(url):\n",
        "    # Send a GET request to the URL\n",
        "    response = requests.get(url)\n",
        "\n",
        "    # Check if the request was successful\n",
        "    if response.status_code == 200:\n",
        "        # Parse the HTML content of the page\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Find the section containing former presidents\n",
        "        former_presidents_section = soup.find('div', class_='block block-system block-system-main-block')\n",
        "\n",
        "        # Check if the section exists\n",
        "        if former_presidents_section:\n",
        "            # Initialize lists to store names and tenures\n",
        "            names = []\n",
        "            tenures = []\n",
        "\n",
        "            # Extract details for each former president\n",
        "            presidents = former_presidents_section.find_all('div', class_='desc-sec')\n",
        "            for president in presidents:\n",
        "                # Extract name\n",
        "                name = president.find('h3').text.strip()\n",
        "                names.append(name)\n",
        "\n",
        "                # Extract tenure\n",
        "                tenure = president.find('h5').text.strip()\n",
        "                tenures.append(tenure)\n",
        "\n",
        "            # Print the list of former presidents and their tenures\n",
        "            for i in range(len(names)):\n",
        "                print(f\"Name of President: {names[i]}\")\n",
        "                print(f\"Tenure of President: {tenures[i]}\")\n",
        "                print()\n",
        "        else:\n",
        "            print(\"Former presidents section not found on the page.\")\n",
        "    else:\n",
        "        print(\"Failed to retrieve the page.\")\n",
        "\n",
        "# URL of the website containing former presidents\n",
        "url = \"https://presidentofindia.nic.in/former-presidents\"\n",
        "\n",
        "# Call the function to scrape details and display\n",
        "scrape_former_presidents(url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80cEPkZKqL2i",
        "outputId": "752bd2ef-5584-46e9-8adb-1c7f129f176b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name of President: Shri Ram Nath Kovind\n",
            "Tenure of President: 14th President of India\n",
            "\n",
            "Name of President: Shri Pranab Mukherjee\n",
            "Tenure of President: 13th President of India\n",
            "\n",
            "Name of President: Smt Pratibha Devisingh Patil\n",
            "Tenure of President: 12th President of India\n",
            "\n",
            "Name of President: DR. A.P.J. Abdul Kalam\n",
            "Tenure of President: 11th President of India\n",
            "\n",
            "Name of President: Shri K. R. Narayanan\n",
            "Tenure of President: 10th President of India\n",
            "\n",
            "Name of President: Dr Shankar Dayal Sharma\n",
            "Tenure of President: 9th  President of India\n",
            "\n",
            "Name of President: Shri R Venkataraman\n",
            "Tenure of President: 8th President of India\n",
            "\n",
            "Name of President: Giani Zail Singh\n",
            "Tenure of President: 7th President of India\n",
            "\n",
            "Name of President: Shri Neelam Sanjiva Reddy\n",
            "Tenure of President: 6th President of India\n",
            "\n",
            "Name of President: Dr. Fakhruddin Ali Ahmed\n",
            "Tenure of President: 5th President of India\n",
            "\n",
            "Name of President: Shri Varahagiri Venkata Giri\n",
            "Tenure of President: 4th President of India\n",
            "\n",
            "Name of President: Dr. Zakir Husain\n",
            "Tenure of President: 3rd President of India\n",
            "\n",
            "Name of President: Dr. Sarvepalli Radhakrishnan\n",
            "Tenure of President: 2nd President of India\n",
            "\n",
            "Name of President: Dr. Rajendra Prasad\n",
            "Tenure of President: 1st President of India\n",
            "\n"
          ]
        }
      ]
    }
  ]
}